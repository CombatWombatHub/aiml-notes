{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47703f4",
   "metadata": {},
   "source": [
    "# Getting Started with NLP\n",
    "- [Getting Started with NLP for Absolute Beginners](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners)\n",
    "- first tutorial in the Kaggle [Natural Language Processing Guide](https://www.kaggle.com/learn-guide/natural-language-processing)\n",
    "\n",
    "## NLP For Classification\n",
    "One of the more useful applications of NLP. Can be used for a bunch of stuff like organizing documents by topic or Sentiment Analysis (finding out if people are saying *positive* or *negative* stuff about your product)\n",
    "\n",
    "## [U.S. Patent Phrase to Phrase Matching Competition](https://www.kaggle.com/c/us-patent-phrase-to-phrase-matching)\n",
    "- compare two words or short phrases\n",
    "    - original competition:\n",
    "        - score them `0`-`1` based on whether they're similar or not\n",
    "        - `0` = totally different meaning, `1` = identical meaning, `0.5` = somewhat similar meaning\n",
    "    - classification version (what we'll do here)\n",
    "        - classify the pairs of words or phrases into `Different`, `Similar`, or `Identical` categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9364bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7417b5f",
   "metadata": {},
   "source": [
    "### Get the Dataset\n",
    "- we'll be getting the dataset from Kaggle. \n",
    "    - One problem - when you go to download a data set from a Kaggle competition, you need to agree to the competition rules, including a rule to *not* make the data available to people who haven't agreed to the competition rules. So I can't just add it to my *publicly-available* repo.\n",
    "    - I could just download it from the webpage manually and put it in the right place, but since I can't add it to tracked files, I'd need to re-do that manually for any notebooks that I'd done that for previously anytime I cloned the repo down.\n",
    "- Instead, [install the Kaggle API](https://github.com/Kaggle/kaggle-api/blob/main/docs/README.md) to download the dataset here so I can import it into this notebook, but don't track it in Git.\n",
    "    - If you haven't already, go to the [Competition page](https://www.kaggle.com/c/us-patent-phrase-to-phrase-matching), go to the `Data` tab, and `Accept` the rules of the competition to be allowed to download the dataset.\n",
    "    - If not already installed, install the API (usually with `pip install kaggle`, but since I'm using `UV` as a dependency manager, I used `uv add kaggle`. Running `uv sync` in this repo should install with all the other dependencies)\n",
    "    - On the [Kaggle website](https://www.kaggle.com/), make or login to your account, Click the Profile picture -> `Settings` -> `API` -> `Create new Token` to download `kaggle.json` to computer.\n",
    "        - Move that file to `~/.kaggle/kaggle.json` (`~` is the home directory)\n",
    "        - note: I use Sphinx with `myst_nb` to turn these notebooks into documentation, and `myst_nb` runs the notebooks to check if they still work. Since I can't commit the `kaggle.json` file to the repo without making my private `kaggle api key` publicly available, specify the API key with environment variables instead: `KAGGLE_USERNAME` and `KAGGLE_KEY`. Get those values out of the `kaggle.json` and add them to [GitHub Secrets for the Github Actions Pipeline to use](https://docs.github.com/en/actions/how-tos/write-workflows/choose-what-workflows-do/use-secrets)\n",
    "    - run the cell below to download and unzip the dataset if it doesn't already exist. \n",
    "    - initially this gave me a `\"Forbidden URL\" error` but later it worked. Possibly I hadn't accepted the rules for the competition yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edde0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzip the dataset to this folder if not already downloaded\n",
    "data_dir = Path(\"us-patent-phrase-to-phrase-matching\")\n",
    "if not data_dir.exists():\n",
    "    import kaggle\n",
    "    import zipfile\n",
    "\n",
    "    # download the dataset from Kaggle as zip file\n",
    "    kaggle.api.competition_download_cli(str(data_dir))  \n",
    "    zip_path = data_dir.with_suffix(\".zip\")  # path to the downloaded zip file\n",
    "    zipfile.ZipFile(zip_path).extractall(data_dir)  # unzip the file\n",
    "    zip_path.unlink()  # delete the zip file after unzipping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e555556",
   "metadata": {},
   "source": [
    "### Examine the DataSet\n",
    "- check the [Competition's Data tab on Kaggle](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/data) for info on the dataset you couldn't get from the CSV's\n",
    "- `anchor` and `target` phrases are rated for similarity\n",
    "- `context` is the subject of a patent according to the [Cooperative Patent Classification (CPC)](https://en.wikipedia.org/wiki/Cooperative_Patent_Classification)\n",
    "    - `A47`: Section `A` (`Human Necessities`), Class `47` (`Furniture`). ([A47C](https://www.uspto.gov/web/patents/classification/cpc/html/cpc-A47C.html) would be `chairs; sofas; beds`)\n",
    "    - the  phrases `bird` and `Cape Cod` are much closer in the `context` of a `house` than in normal language\n",
    "- `score` rates how similar the `anchor` and `target` phrases are (created by manual expert ratings)\n",
    "    - `0` = not at all similar\n",
    "    - `1` = identical meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "150d4623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>42d9e032d1cd3242</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>208654ccb9e14fa3</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>756ec035e694722b</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n",
       "...                 ...           ...                     ...     ...    ...\n",
       "36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n",
       "36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n",
       "36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n",
       "36471  756ec035e694722b  wood article         wooden material     B44   0.75\n",
       "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and check the dataset. Looks like it's already scoring similarity of word/phrase pairs.\n",
    "df = pd.read_csv(data_dir / \"train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18d31b",
   "metadata": {},
   "source": [
    "- using `describe()` reveals 36,473 rows \n",
    "- 733 unique `anchor` phrases, \n",
    "- a whopping 29340 unique `target` phrases, \n",
    "- 106 unique `context`s (subject matter). \n",
    "- Some anchors appear a LOT - the `anchor` `component composite coating` appears 152 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cbe9832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get descriptive statistics on the object (string) columns\n",
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b9276",
   "metadata": {},
   "source": [
    "### Concatenate the Input\n",
    "- we'll be representing the input to the model like this\n",
    "- `TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement`\n",
    "- so use `+` to concatenate multiple columns into one \"input\" column \n",
    "- so we'll have one input string per row containing all the important data\n",
    "- I'd forgotten that you can refer to Pandas columns (series's) with dots\n",
    "- i.e. `df['context'] = df.context`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648ff22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TEXT1: A47; TEXT2: abatement of pollution; ANC...\n",
       "1    TEXT1: A47; TEXT2: act of abating; ANC1: abate...\n",
       "2    TEXT1: A47; TEXT2: active catalyst; ANC1: abat...\n",
       "3    TEXT1: A47; TEXT2: eliminating process; ANC1: ...\n",
       "4    TEXT1: A47; TEXT2: forest region; ANC1: abatement\n",
       "Name: input, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# createe an 'input' column by concatenating the important columns with specifiers between\n",
    "df[\"input\"] = \"TEXT1: \" + df.context + \"; TEXT2: \" + df.target + \"; ANC1: \" + df.anchor\n",
    "df.input.head()  # print out the first 5 entries of the new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e769bb",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "- we're going to pass this to a deep learning model\n",
    "    - a neural net expects numbers as inputs, not strings\n",
    "    - must convert these strings to numbers in two steps\n",
    "        - **Tokenization** - split the text into `tokens` (sometimes these are words)\n",
    "        - **Numericalization** - convert each `token` into a number\n",
    "- to connect the bits and bobs of the networks together we'll use a [Hugging Face Transformer](https://huggingface.co/docs/transformers/en/index)\n",
    "    - `Transformers` store their datasets in ... `Dataset` ... objects ...\n",
    "    - take a look at that object after converting to one from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f50eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gillm\\VisualStudioCode\\aiml-notes\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aebb468",
   "metadata": {},
   "source": [
    "- pick an NLP model to start with (the `tokenization` and `numericalization` methods will depend on your model)\n",
    "- the `microsoft/deberta-v3-small` is a decent starting place for most NLP problems\n",
    "- use `microsoft/deberta-v3-large` for a slower but more accurate model (after initial exploration)\n",
    "- these are pre-trained models, already adept at parsing natural language\n",
    "- use the `AutoTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92abe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"G'day folks, I'm Jeremy from fast.ai!\"] ->\n",
      "['▁G', \"'\", 'day', '▁folks', ',', '▁I', \"'\", 'm', '▁Jeremy', '▁from', '▁fast', '.', 'ai', '!']\n",
      "[\"A platypus is an ornithorhynchus anatinus.\"] ->\n",
      "['▁A', '▁platypus', '▁is', '▁an', '▁or', 'ni', 'tho', 'rhynch', 'us', '▁an', 'at', 'inus', '.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_nm = \"microsoft/deberta-v3-small\" # select a pretrained model from Hugging Face model hub\n",
    "# get the tokenization that was used with the pretrained model, make into a tokenizer object to use on our inputs\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm) #, use_fast=False) would use a slower tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b838b0f1",
   "metadata": {},
   "source": [
    "Show how the tokenizer splits text into tokens\n",
    "- uncommon words are split into subwords (like `G'day` → `_G`, `'`, `day`)\n",
    "- `_` is added to the start of new words (distinguishes new words like `_folks` from the `day` in `G'day`)\n",
    "- punctuation like  is treated as separate tokens (like `'`, `,`, `!`, `.`)\n",
    "- uncommon words are split into subwords (like `ornithorynchus` → `▁or`, `ni`, `tho`, `rhynch`, `us`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29856078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"G'day folks, I'm Jeremy from fast.ai!\"] ->\n",
      "['▁G', \"'\", 'day', '▁folks', ',', '▁I', \"'\", 'm', '▁Jeremy', '▁from', '▁fast', '.', 'ai', '!']\n",
      "[\"A platypus is an ornithorhynchus anatinus.\"] ->\n",
      "['▁A', '▁platypus', '▁is', '▁an', '▁or', 'ni', 'tho', 'rhynch', 'us', '▁an', 'at', 'inus', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[\\\"G'day folks, I'm Jeremy from fast.ai!\\\"] ->\")\n",
    "print(tokz.tokenize(\"G'day folks, I'm Jeremy from fast.ai!\"))\n",
    "print(\"[\\\"A platypus is an ornithorhynchus anatinus.\\\"] ->\")\n",
    "print(tokz.tokenize(\"A platypus is an ornithorhynchus anatinus.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b374f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 36473/36473 [00:00<00:00, 59226.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original  columns: ['id', 'anchor', 'target', 'context', 'score', 'input']\n",
      "tokenized columns: ['id', 'anchor', 'target', 'context', 'score', 'input', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define a function to apply the tokenizer to the 'input' column of the dataset\n",
    "def tok_func(x): return tokz(x[\"input\"])\n",
    "# use map to run the tokenizer function quickly on the dataset, in parallel batches for speed\n",
    "tok_ds = ds.map(tok_func, batched=True)\n",
    "# that added the columns input_ids, token_type_ids, attention_mask\n",
    "print(\"original  columns:\", ds.column_names)\n",
    "print(\"tokenized columns:\", tok_ds.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2be0b",
   "metadata": {},
   "source": [
    "Look at the columns that were added by the tokenization\n",
    "- these columns have lists in each cell\n",
    "- `input_ids` are the number assigned to a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c082a20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \"TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement\"\n",
      "vocab of token 'of': 435\n",
      "\n",
      "     token  input_ids  attention_mask  token_type_ids\n",
      "                    1               1               0\n",
      "     ▁TEXT      54453               1               0\n",
      "         1        435               1               0\n",
      "         :        294               1               0\n",
      "        ▁A        336               1               0\n",
      "        47       5753               1               0\n",
      "         ;        346               1               0\n",
      "     ▁TEXT      54453               1               0\n",
      "         2        445               1               0\n",
      "         :        294               1               0\n",
      "▁abatement      47284               1               0\n",
      "       ▁of        265               1               0\n",
      "▁pollution       6435               1               0\n",
      "         ;        346               1               0\n",
      "      ▁ANC      23702               1               0\n",
      "         1        435               1               0\n",
      "         :        294               1               0\n",
      "▁abatement      47284               1               0\n",
      "                    2               1               0\n"
     ]
    }
   ],
   "source": [
    "# look at the columns that the tokenization added for the first row\n",
    "row = tok_ds[0]\n",
    "input_row = row['input']\n",
    "tk_df = pd.DataFrame({\n",
    "    'token': [''] + tokz.tokenize(row['input']) + [''], # there are extra start and end id's\n",
    "    'input_ids': row['input_ids'],\n",
    "    'attention_mask': row['attention_mask'],\n",
    "    'token_type_ids': row['token_type_ids'],\n",
    "})\n",
    "print(\"input:\", f\"\\\"{row['input']}\\\"\")\n",
    "print(f\"vocab of token 'of': {tokz.vocab['1']}\\n\")\n",
    "print(tk_df.to_string(index=False))  # print the whole dataframe without truncating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d92560",
   "metadata": {},
   "source": [
    "### Prepare Labels\n",
    "- `Transformers` assume that the labels column is named `labels`\n",
    "- rename the `score` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea8904cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_ds = tok_ds.rename_column(\"score\", \"labels\")  # rename the score column to labels\n",
    "tok_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ac389",
   "metadata": {},
   "source": [
    "### Get Test and Validation Sets\n",
    "- the `train` set is used to ... train ... the model\n",
    "- the `validation` set is used to select the `architecture` and for `hyperparameter tuning`\n",
    "- the `test` set is *completely unseen* and scores how well the model will generalize to real world data\n",
    "\n",
    "#### Validation Set\n",
    "- split off some of the test data to use for `validation`\n",
    "    - use it for `architecture selection` / `hyperparameter tuning`\n",
    "    - note that you can `overfit` to the `validation data` as well as the `training data`\n",
    "    - that's where the `test` set comes in - it can help check for `overfitting`\n",
    "- we're doing it randomly here, but apparently choosing a *good* validation set is one of *the* most important parts of training\n",
    "    - if you do a random set, sometimes there are differences between development and production use\n",
    "    - see the article [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/) by Dr. Rachel Thomas\n",
    "\n",
    "#### Test Set\n",
    "- import the test data set (36 entries)\n",
    "    - often we split it off ourself, but Kaggle gives you a separate one already\n",
    "    - your accuracy at predicting with this set goes on the *public leaderboard*\n",
    "- in addition, Kaggle keeps a *second* test data set that they bring out at the *end* of a competition\n",
    "    - if you overfit to the public leaderboard test data, you could lose ability to generalize to the holdout set\n",
    "    - this one is called the *private leaderboard*\n",
    "- they note that you can even `overfit` to the `test set` ... yikes, sounds unavoidable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef28b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>hybrid bearing</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id          anchor                         target  \\\n",
       "count                 36              36                             36   \n",
       "unique                36              34                             36   \n",
       "top     4112d61851461f60  hybrid bearing  inorganic photoconductor drum   \n",
       "freq                   1               2                              1   \n",
       "\n",
       "       context  \n",
       "count       36  \n",
       "unique      29  \n",
       "top        G02  \n",
       "freq         3  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the CSV with all the test data \n",
    "# (name it \"eval\" to avoid confusion with the \"test\" split of the training data)\n",
    "eval_df = pd.read_csv(data_dir / 'test.csv')\n",
    "eval_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1694f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split off a quarter of the training data to use as a validation set\n",
    "dds = tok_ds.train_test_split(0.25, seed=42)\n",
    "dds\n",
    "# NOTE: it's automatically named \"test\" instead of \"validation\", don't mix it up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd1365",
   "metadata": {},
   "source": [
    "### Metrics and Correlation\n",
    "- while `training`, we're generally minimizing or maximizing one or more `metrics`\n",
    "- you can't apply them unthinkingly - see [The Problem with Metrics is a Big problem for AI](https://www.fast.ai/2019/09/24/metrics/)\n",
    "- Kaggle Competitions have specific metrics already defined so everyone is scored the same way\n",
    "- they're listed on the Competition's [Evaluation Page](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/overview/evaluation), in this case the [Pearson Correlation Coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "    - it measures correlation between two variables\n",
    "        - it varies from `-1` (perfect inverse correlation) to `1` (perfect positive correlation)\n",
    "        - it's the [covariance](https://en.wikipedia.org/wiki/Covariance) (joint variability) of the two variables divided by the product of their standard deviations\n",
    "    - the equation is on the complicated side, and there's a different one for populations\n",
    "        - $\\rho_{X,Y}=\\Large\\frac{cov(X,Y)}{\\sigma_X \\sigma_Y}$\n",
    "    - vs for samples\n",
    "        - $r_{xy}=\\Large\\frac{\\sum^n_{i=1}{(x_i - \\bar x)(y_i - \\bar y)}}{\\sqrt{\\sum^n_{i=1} (x_i - \\bar x)^2}\\sqrt{\\sum^n_{i=1} (y_i - \\bar y)^2}}$\n",
    "- the example notebook doesn't list the formulas\n",
    "    - but it does goes over the correlation in more detail in the section [Metrics and Correlation](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners#metrics-and-correlation)\n",
    "    - this mostly involves checking it on other datasets, so I'm not replicating that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to calculate Pearson correlation coefficient\n",
    "# corrcoeff returns a 2x2 array, just grab the [0][1] element \n",
    "# which is the correlation between variables x and y\n",
    "import numpy as np\n",
    "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
    "\n",
    "# Transformers expect metrics to be returned as a dictionary\n",
    "# Create a function to return a dictionary for the metric\n",
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86159c",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml-notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
