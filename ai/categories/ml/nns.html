
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Neural Networks &#8212; aiml-notes 1.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=43d83c71" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=a681ed88"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ai/categories/ml/nns';</script>
    <link rel="icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Physics-Informed Neural Networks (PINNs)" href="pinns.html" />
    <link rel="prev" title="Dimensionality Reduction" href="dimensionality_reduction.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.jpg" class="logo__image only-light" alt="aiml-notes 1.0 documentation - Home"/>
    <script>document.write(`<img src="../../../_static/logo.jpg" class="logo__image only-dark" alt="aiml-notes 1.0 documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../index.html">
                    AI/ML Notes
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes:</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Categories</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../generative.html">Generative AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="dimensionality_reduction.html">Dimensionality Reduction</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="pinns.html">Physics-Informed Neural Networks (PINNs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm.html">SVM (Support Vector Machines)</a></li>
<li class="toctree-l2"><a class="reference internal" href="xai.html">Explainable AI (XAI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp.html">Natural Language Processing</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../development/index.html">Development</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../development/developing.html">ML Development</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../development/fundamentals.html">Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../development/math.html">Required Math</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../development/metrics.html">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../development/resources.html">Resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../development/tokenization.html">Tokenization</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../libraries/index.html">Libraries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/pytorch.html">Learning Pytorch</a></li>


</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Portfolio:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../portfolio/portfolio.html">Portfolio</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../portfolio/kaggle/index.html">Kaggle</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../portfolio/kaggle/iterate_like_a_grandmaster/iterate_like_a_grandmaster.html">Iterate Like a Grandmaster</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../portfolio/kaggle/metrics.html">Metrics and correlation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../portfolio/kaggle/nlp_beginners_guide/nlp_beginners_guide_noex.html">Getting Started with NLP</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../portfolio/machine_learning_mastery/index.html">Machine Learning Mastery</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../portfolio/machine_learning_mastery/python_ml_mini_course/python_ml_mini_course.html">Python Mini Course</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../portfolio/datacamp/index.html">DataCamp</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../portfolio/datacamp/supervised_learning_scikit_learn/supervised_learning_scikit_learn.html">Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../portfolio/datacamp/using_datacamp.html">Using DataCamp</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../portfolio/geeksforgeeks/index.html">Geeks for Geeks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../portfolio/geeksforgeeks/text-classification-scikit-learn.html">Text Classification using scikit-learn in NLP</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../portfolio/shap/index.html">SHAP</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../portfolio/shap/shapley_xai_intro.html">An introduction to explainable AI with Shapley values</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Sphinx:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../sphinx_examples/index.html">Sphinx</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../sphinx_examples/markdown.html">Markdown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../sphinx_examples/notebook.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../sphinx_examples/restructuredtext.html">reStructuredText</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/CombatWombatHub/aiml-notes" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/ai/categories/ml/nns.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tiny-neural-network">Tiny Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation">Backpropagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">Activation Functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties">Properties</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#derivatives">Derivatives</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="neural-networks">
<h1>Neural Networks<a class="headerlink" href="#neural-networks" title="Link to this heading">#</a></h1>
<section id="tiny-neural-network">
<h2>Tiny Neural Network<a class="headerlink" href="#tiny-neural-network" title="Link to this heading">#</a></h2>
<p>Behold, I created a tiny neural network, showing nodes, activation functions, matrices, and equations.</p>
<p><img alt="tiny neural network" src="../../../_images/tiny_neural_network.png" /></p>
<ul class="simple">
<li><p>layer values</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(X=\)</span> vector of inputs</p></li>
<li><p><span class="math notranslate nohighlight">\(W^{[1]}=\)</span> matrix of weights of hidden layer 1</p></li>
<li><p><span class="math notranslate nohighlight">\(B^{[1]}=\)</span> vector of biases of hidden layer 1</p></li>
<li><p><span class="math notranslate nohighlight">\(Z^{[1]}=\)</span> vector of inputs to hidden layer 1, with weights and biases applied</p></li>
<li><p><span class="math notranslate nohighlight">\(A^{[1]}=\)</span> vector of outputs from hidden layer 1, with activation function applied</p></li>
</ul>
</li>
<li><p>node values</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(x_2=\)</span> input from node 2</p></li>
<li><p><span class="math notranslate nohighlight">\(w^{[1]}_{23}=\)</span> weight from node 2 to node 3 of layer 1</p></li>
<li><p><span class="math notranslate nohighlight">\(b^{[1]}_2=\)</span> bias of node 2 of hidden layer 1</p></li>
<li><p><span class="math notranslate nohighlight">\(z^{[1]}_2=\)</span> input to node 2 of hidden layer 1, created by summing weighted inputs</p></li>
<li><p><span class="math notranslate nohighlight">\(a^{[1]}_2=\)</span> output from node 2 of layer 1</p></li>
</ul>
</li>
<li><p>not pictured</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(m^{[1]},\cdots,m^{[r]}=\)</span> number of neurons in <span class="math notranslate nohighlight">\(1^{st}\)</span> through <span class="math notranslate nohighlight">\(r^{th}\)</span> (final) hidden layers</p></li>
<li><p><span class="math notranslate nohighlight">\(g^{[1]},\cdots,g^{[r]}=\)</span> activation functions of <span class="math notranslate nohighlight">\(1^{st}\)</span> through <span class="math notranslate nohighlight">\(r^{th}\)</span> (final) hidden layers</p></li>
</ul>
</li>
<li><p>note</p>
<ul>
<li><p>you transpose the weights (<span class="math notranslate nohighlight">\(W^{[1]T}\)</span> or <span class="math notranslate nohighlight">\(W^{[2]T}\)</span>) before multiplying by inputs (<span class="math notranslate nohighlight">\(X\)</span> or <span class="math notranslate nohighlight">\(A^{[1]}\)</span>) as inner dimensions must match for matrix multiplication</p></li>
</ul>
</li>
</ul>
</section>
<section id="backpropagation">
<h2>Backpropagation<a class="headerlink" href="#backpropagation" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>backpropagation is the process by which you determine how to update weights to minimize loss (shown here as the cost function J)</p></li>
<li><p>you take partial derivatives of each step in the network, then combine them with the chain rule to get the derivative of the loss with respect to each individual weight</p></li>
<li><p>then you multiply the weight by that gradient and the learning rate so that the next training batch will hopefully have reduced loss</p></li>
</ul>
<p><img alt="backpropogation" src="../../../_images/network_backpropagation_schematic.jpg" /></p>
</section>
<section id="activation-functions">
<h2><a class="reference external" href="https://en.wikipedia.org/wiki/Activation_function">Activation Functions</a><a class="headerlink" href="#activation-functions" title="Link to this heading">#</a></h2>
<p>Functions that determine the output of a node from the summed, weighted,biased inputs. Different layers can have different activation functions.</p>
<section id="properties">
<h3>Properties<a class="headerlink" href="#properties" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Nonlinear</strong> - if the activation function is <code class="docutils literal notranslate"><span class="pre">nonlinear</span></code>, a two-layer neural network can be a universal function approximator. The <code class="docutils literal notranslate"><span class="pre">identity</span></code> activation function (basically meaning no activation function at all) will severely limit what your network can approximate, showing why we use activation functions.</p></li>
<li><p><strong>Range</strong> - if the activation function’s output range is finite (like how a <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> function ranges from <code class="docutils literal notranslate"><span class="pre">(0,1)</span></code> or a <code class="docutils literal notranslate"><span class="pre">tanh</span></code> function ranges from <code class="docutils literal notranslate"><span class="pre">(-1,1)</span></code>), gradient-based training methods tend to be more stable. If not (like how <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> can increase infinitely with the input), training tends to be more efficient as patterns in the data can affect more weights and may help avoid the vanishing gradients problem (though you should use smaller learning rates in this case).</p></li>
<li><p><strong>Continouously Differentiable</strong> - continuously-differentiable activation functions have easier times with gradient-based optimization methods. Some non-continuously-differentiable activation functions which suddenly change directions (like <code class="docutils literal notranslate"><span class="pre">ReLU</span></code>) may have issues with gradient-based optimization, but can still be used.</p></li>
</ul>
</section>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Link to this heading">#</a></h3>
<p>There are a <strong>LOT</strong> of different activation functions - here are a few (see this <a class="reference external" href="https://en.wikipedia.org/wiki/Activation_function#Table_of_activation_functions">table</a> for more)</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">linear</span></code> - <span class="math notranslate nohighlight">\(y=mx+b\)</span> - basically the output is just a line relative to the input, does not allow the network to be a universal function approximator. All of the other functions shown are <code class="docutils literal notranslate"><span class="pre">nonlinear</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> (<code class="docutils literal notranslate"><span class="pre">&quot;logistic&quot;</span></code>) - <span class="math notranslate nohighlight">\(\sigma\)</span> - squashes the real number into a <code class="docutils literal notranslate"><span class="pre">(0,1)</span></code> range.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ReLU</span></code> - <a class="reference external" href="https://en.wikipedia.org/wiki/Rectified_linear_unit">Rectified Linear Unit</a> - provides the same benefits as sigmoid but with less computational effort. One of the most popular activation functions with many variants</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Leaky</span> <span class="pre">ReLU</span></code> - allows a small positive gradient “<span class="math notranslate nohighlight">\(\alpha\)</span>” (usually <code class="docutils literal notranslate"><span class="pre">0.01-0.3</span></code>) when the unit is inactive to counteract the vanishing gradient problem</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PReLU</span></code> - <code class="docutils literal notranslate"><span class="pre">Parametric</span> <span class="pre">Rectified</span> <span class="pre">Linear</span> <span class="pre">Unit</span></code> - makes “<span class="math notranslate nohighlight">\(\alpha\)</span>” a learnable parameter along with other parameters like weights</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GELU</span></code> - <code class="docutils literal notranslate"><span class="pre">Gaussian</span> <span class="pre">Error</span> <span class="pre">Linear</span> <span class="pre">Unit</span></code> - smooth apporoximation of <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> with a “bump”. default activation for many transformer models such as <a class="reference external" href="https://en.wikipedia.org/wiki/BERT_(language_model)">BERT</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SiLU</span></code> (<code class="docutils literal notranslate"><span class="pre">&quot;swish&quot;</span></code>) - <code class="docutils literal notranslate"><span class="pre">Sigmoid</span> <span class="pre">Linear</span> <span class="pre">Unit</span></code> - another smooth approximation with a bump, uses the <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> function, cheaper to calculate than <code class="docutils literal notranslate"><span class="pre">GELU</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tanh</span></code> - <code class="docutils literal notranslate"><span class="pre">Hyperbolic</span> <span class="pre">Tangent</span></code> - nonlinear, zero-centered, squashes the real number into a <code class="docutils literal notranslate"><span class="pre">(-1,1)</span></code> range, faster convergence than <code class="docutils literal notranslate"><span class="pre">sinusoid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sinusoid</span></code> - a periodic activation function. <code class="docutils literal notranslate"><span class="pre">sin</span></code> is usually used as any periodic function is decomposable into sinusoids by <a class="reference external" href="https://en.wikipedia.org/wiki/Fourier_transform">Fourier transform</a>. increasing-order derivatives never go to zero. Periodicity may make convergence difficult.</p></li>
</ul>
<p><img alt="activation functions" src="../../../_images/activation_functions.png" /></p>
</section>
<section id="derivatives">
<h3>Derivatives<a class="headerlink" href="#derivatives" title="Link to this heading">#</a></h3>
<p>Note that if you’re using PINN’s or something with autodifferentiation, any non-periodic activation functions will decrease in magnitude with each derivative</p>
<p><img alt="activation function derivatives" src="../../../_images/activation_functions_sigmoid_derivatives.png" /></p>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="dimensionality_reduction.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Dimensionality Reduction</p>
      </div>
    </a>
    <a class="right-next"
       href="pinns.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Physics-Informed Neural Networks (PINNs)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tiny-neural-network">Tiny Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation">Backpropagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">Activation Functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties">Properties</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#derivatives">Derivatives</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Matthew T Gill
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>